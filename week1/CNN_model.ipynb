{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4o4slguglY8i",
        "outputId": "19fdb712-263c-4747-f953-ebbddcc72339",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print(\"gpu\")\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_5EnA3AAqq1",
        "outputId": "3d5ce486-dd0c-4d17-f144-3fe578a6d0f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "train_dataset = dsets.FashionMNIST(root='./data', \n",
        "                            train=True, \n",
        "                            transform=transforms.ToTensor(),\n",
        "                            download=True)\n",
        "\n",
        "test_dataset = dsets.FashionMNIST(root='./data', \n",
        "                           train=False, \n",
        "                           transform=transforms.ToTensor())\n",
        "print(train_dataset.train_data.size())\n",
        "print(test_dataset.test_data.size())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([60000, 28, 28])\n",
            "torch.Size([10000, 28, 28])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:55: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:60: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcmEPsobAZA3"
      },
      "source": [
        "classes = ('T-Shirt','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle Boot')\n",
        "def imshow(img):\n",
        "    npimg = img.numpy() #convert the tensor to numpy for displaying the image\n",
        "    #for displaying the image, shape of the image should be height * width * channels \n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0))) \n",
        "    plt.show()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76WGRtHTBO8l"
      },
      "source": [
        ""
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-13ExLnDlxe"
      },
      "source": [
        "batch_size = 100\n",
        "n_iters = 3000\n",
        "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pDHjxvvGAgG"
      },
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, width):\n",
        "        super(CNNModel, self).__init__()\n",
        "\n",
        "        # Convolution 1\n",
        "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "        # Max pool 1\n",
        "        # self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        # Convolution 2\n",
        "        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "        # Max pool 2\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        # Fully connected 1 (readout)\n",
        "        kernel = 3\n",
        "        kernel_max2 = 2\n",
        "        stride1,stride2 = 1,1\n",
        "        width_cnn1 = math.ceil((width-kernel+2)/stride1 + 1 )\n",
        "        print(\"width_cnn1: \", width_cnn1)\n",
        "        width_cnn2 = math.ceil((width_cnn1-kernel+2)/stride2 + 1 )\n",
        "        print(\"width_cnn2: \", width_cnn2)\n",
        "        width_max2 = math.ceil((width_cnn2-kernel_max2)/kernel_max2 + 1)\n",
        "        print(\"width_max2: \", width_max2)\n",
        "        self.fc1 = nn.Linear(32 * width_max2 * width_max2, 128)\n",
        "        self.relu3 = nn.ReLU() \n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "    def forward(self, x):\n",
        "        # Convolution 1\n",
        "        # print(\"x size: \", x.size())\n",
        "        out = self.cnn1(x)\n",
        "        # print(\"cnn1 size: \", out.size())\n",
        "        out = self.relu1(out)\n",
        "        # print(\"relu1 size: \", out.size())\n",
        "        # Max pool 1\n",
        "        # print(\"bef: \", out.size())\n",
        "        # out = self.maxpool1(out)\n",
        "        # print(\"aft: \", out.size())\n",
        "        # Convolution 2 \n",
        "        out = self.cnn2(out)\n",
        "        # print(\"cnn2 size: \", out.size())\n",
        "        out = self.relu2(out)\n",
        "        # print(\"rel2 size: \", out.size())\n",
        "        # Max pool 2 \n",
        "        out = self.maxpool2(out)\n",
        "        # print(\"max2 size: \", out.size())\n",
        "        # Resize\n",
        "        # Original size: (100, 32, 7, 7)\n",
        "        # out.size(0): 100\n",
        "        # New out size: (100, 32*7*7)\n",
        "        out = out.view(out.size(0), -1)\n",
        "\n",
        "        # Linear function (readout)\n",
        "        # print(\"view size: \", out.size())\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu3(out)\n",
        "\n",
        "        #dropout\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        #linear func\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-xvD2DnfUdS",
        "outputId": "73f5e6db-1f76-477c-a113-ca3a8a11baf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "model = CNNModel(28)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "learning_rate = 0.01\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "width_cnn1:  28\n",
            "width_cnn2:  28\n",
            "width_max2:  14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNLWmtYdfulq",
        "outputId": "0fe619a5-d281-4681-88cb-5d6c380b556e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "print(model.parameters())\n",
        "\n",
        "print(len(list(model.parameters())))\n",
        "\n",
        "# Convolution 1: 16 Kernels\n",
        "print(list(model.parameters())[0].size())\n",
        "\n",
        "# Convolution 1 Bias: 16 Kernels\n",
        "print(list(model.parameters())[1].size())\n",
        "\n",
        "# Convolution 2: 32 Kernels with depth = 16\n",
        "print(list(model.parameters())[2].size())\n",
        "\n",
        "# Convolution 2 Bias: 32 Kernels with depth = 16\n",
        "print(list(model.parameters())[3].size())\n",
        "\n",
        "# Fully Connected Layer 1\n",
        "print(list(model.parameters())[4].size())\n",
        "\n",
        "# Fully Connected Layer Bias\n",
        "print(list(model.parameters())[5].size())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<generator object Module.parameters at 0x7f7a1034c518>\n",
            "8\n",
            "torch.Size([16, 1, 3, 3])\n",
            "torch.Size([16])\n",
            "torch.Size([32, 16, 3, 3])\n",
            "torch.Size([32])\n",
            "torch.Size([128, 6272])\n",
            "torch.Size([128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYeIjSMrgL6H",
        "outputId": "872a91e7-f3ed-4f5e-8a1c-db4f7da0d5db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "iter = 0\n",
        "for epoch in range(10):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Load images\n",
        "        images = images.requires_grad_().to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model(images)\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 500 == 0:\n",
        "            # Calculate Accuracy         \n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "                # Load images\n",
        "                images = images.requires_grad_().to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(images)\n",
        "\n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "                # Total number of labels\n",
        "                total += labels.size(0)\n",
        "\n",
        "                #######################\n",
        "                #  USE GPU FOR MODEL  #\n",
        "                #######################\n",
        "                # Total correct predictions\n",
        "                if torch.cuda.is_available():\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum()\n",
        "                else:\n",
        "                    correct += (predicted == labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct // total\n",
        "\n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 500. Loss: 0.6801870465278625. Accuracy: 72\n",
            "Iteration: 1000. Loss: 0.44436731934547424. Accuracy: 77\n",
            "Iteration: 1500. Loss: 0.5709998607635498. Accuracy: 81\n",
            "Iteration: 2000. Loss: 0.5649828910827637. Accuracy: 81\n",
            "Iteration: 2500. Loss: 0.42584770917892456. Accuracy: 82\n",
            "Iteration: 3000. Loss: 0.40394797921180725. Accuracy: 82\n",
            "Iteration: 3500. Loss: 0.5769420266151428. Accuracy: 83\n",
            "Iteration: 4000. Loss: 0.44504815340042114. Accuracy: 83\n",
            "Iteration: 4500. Loss: 0.450328528881073. Accuracy: 83\n",
            "Iteration: 5000. Loss: 0.2917686700820923. Accuracy: 83\n",
            "Iteration: 5500. Loss: 0.4468529224395752. Accuracy: 84\n",
            "Iteration: 6000. Loss: 0.3932793438434601. Accuracy: 84\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}