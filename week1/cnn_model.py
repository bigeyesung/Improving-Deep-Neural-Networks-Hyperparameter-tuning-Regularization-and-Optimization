# -*- coding: utf-8 -*-
"""CNN model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1n0sKGW6igW0KXCMiRbMwB8-TVamWJMjc
"""

import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
import torchvision.datasets as dsets
import matplotlib.pyplot as plt
import math
if torch.cuda.is_available():
    device = torch.device('cuda')
    print("gpu")

train_dataset = dsets.FashionMNIST(root='./data', 
                            train=True, 
                            transform=transforms.ToTensor(),
                            download=True)

test_dataset = dsets.FashionMNIST(root='./data', 
                           train=False, 
                           transform=transforms.ToTensor())
print(train_dataset.train_data.size())
print(test_dataset.test_data.size())

classes = ('T-Shirt','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle Boot')
def imshow(img):
    npimg = img.numpy() #convert the tensor to numpy for displaying the image
    #for displaying the image, shape of the image should be height * width * channels 
    plt.imshow(np.transpose(npimg, (1, 2, 0))) 
    plt.show()



#Batch：每批丟入多少張圖片
batch_size = 100
n_iters = 3000
num_epochs = n_iters / (len(train_dataset) / batch_size)
num_epochs = int(num_epochs)

train_loader = torch.utils.data.DataLoader(dataset=train_dataset, 
                                           batch_size=batch_size, 
                                           shuffle=True)

test_loader = torch.utils.data.DataLoader(dataset=test_dataset, 
                                          batch_size=batch_size, 
                                          shuffle=False)
print(len(train_loader))
print(len(test_loader))
for i, (images, labels) in enumerate(train_loader):
  print(len(images))
  break

class CNNModel(nn.Module):
    def __init__(self, width, drop):
        super(CNNModel, self).__init__()

        # Convolution 1
        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)
        self.relu1 = nn.ReLU()

        # Max pool 1
        # self.maxpool1 = nn.MaxPool2d(kernel_size=2)

        # Convolution 2
        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)
        self.relu2 = nn.ReLU()

        # Max pool 2
        self.maxpool2 = nn.MaxPool2d(kernel_size=2)

        # Fully connected 1 (readout)
        kernel = 3
        kernel_max2 = 2
        stride1,stride2 = 1,1
        width_cnn1 = math.ceil((width-kernel+2)/stride1 + 1 )
        print("width_cnn1: ", width_cnn1)
        width_cnn2 = math.ceil((width_cnn1-kernel+2)/stride2 + 1 )
        print("width_cnn2: ", width_cnn2)
        width_max2 = math.ceil((width_cnn2-kernel_max2)/kernel_max2 + 1)
        print("width_max2: ", width_max2)
        self.fc1 = nn.Linear(32 * width_max2 * width_max2, 128)
        self.relu3 = nn.ReLU() 
        self.dropout = nn.Dropout(p=drop)
        self.fc2 = nn.Linear(128, 10)
    def forward(self, x):
        # Convolution 1
        # print("x size: ", x.size())
        out = self.cnn1(x)
        # print("cnn1 size: ", out.size())
        out = self.relu1(out)
        # print("relu1 size: ", out.size())

        # Convolution 2 
        out = self.cnn2(out)
        # print("cnn2 size: ", out.size())
        out = self.relu2(out)
        # print("rel2 size: ", out.size())

        # Max pool 2 
        out = self.maxpool2(out)
        # print("max2 size: ", out.size())

        # Resize
        # Original size: (100, 32, 7, 7)
        # out.size(0): 100
        # New out size: (100, 32*7*7)
        # Flattern the convolution output
        out = out.view(out.size(0), -1)

        # Linear function (readout)
        out = self.fc1(out)
        out = self.relu3(out)

        #dropout
        out = self.dropout(out)

        #linear func
        out = self.fc2(out)
        # print("final out: ", out.size())
        return out

# model = CNNModel(28, 0.2)
# device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
# model.to(device)

# criterion = nn.CrossEntropyLoss()
# # Change learning rate
# learning_rate = 0.01
# # Try SGD, Adam.... etc 
# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)

print(len(list(model.parameters())))
for n in range(len(list(model.parameters()))):
    print(list(model.parameters())[n].size())


# # Convolution 1: 16 Kernels
# print(list(model.parameters())[0].size())

# # Convolution 1 Bias: 16 Kernels
# print(list(model.parameters())[1].size())

# # Convolution 2: 32 Kernels with depth = 16
# print(list(model.parameters())[2].size())

# # Convolution 2 Bias: 32 Kernels with depth = 16
# print(list(model.parameters())[3].size())

# # Fully Connected Layer 1
# print(list(model.parameters())[4].size())

# # Fully Connected Layer Bias
# print(list(model.parameters())[5].size())

dropout = [0.0, 0.5, 0.7, 0.9, 0.99, 0.999]
for num in dropout:
  model = CNNModel(28, num)
  device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
  model.to(device)
  criterion = nn.CrossEntropyLoss()
  # Change learning rate
  learning_rate = 0.01
  # Try SGD, Adam.... etc 
  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  

  iter = 0
  train_losses, test_losses = [], []
  running_loss = 0
  for epoch in range(10):
      for i, (images, labels) in enumerate(train_loader):
          # Load images
          images = images.requires_grad_().to(device)
          labels = labels.to(device)

          # Clear gradients w.r.t. parameters
          optimizer.zero_grad()
          # Forward pass to get output/logits
          outputs = model(images)
          # Calculate Loss: softmax --> cross entropy loss
          loss = criterion(outputs, labels)
          # Getting gradients w.r.t. parameters
          loss.backward()
          # Updating parameters
          optimizer.step()

          iter += 1
          running_loss += loss.item()

          if iter % 600 == 0:
              test_loss = 0
              # Calculate Accuracy         
              correct = 0
              total = 0
              model.eval()
              # Iterate through test dataset
              for images, labels in test_loader:
                  # Load images
                  images = images.requires_grad_().to(device)
                  labels = labels.to(device)

                  # Forward pass only to get logits/output
                  outputs = model(images)
                  batch_loss = criterion(outputs, labels)
                  test_loss += batch_loss.item()

                  # Get predictions from the maximum value
                  _, predicted = torch.max(outputs.data, 1)
                  # print("predicted: ", predicted)
                  # Total number of labels
                  total += labels.size(0)

                  # Total correct predictions
                  # if torch.cuda.is_available():
                  correct += (predicted.cpu() == labels.cpu()).sum()
                  # else:
                  #     correct += (predicted == labels).sum()

              accuracy = 100 * correct // total
              train_losses.append(running_loss/len(train_loader))
              test_losses.append(test_loss/len(test_loader))   
              # Print Loss
              print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))
              running_loss = 0
              model.train()
  plt.plot(train_losses, label='Training loss')
  plt.plot(test_losses, label='Validation loss')
  plt.title("chenhsi_model_"+str(num))
  plt.legend(frameon=False)
  plt.show()
  #save model
  torch.save(model, "chenhsi_model_"+str(num))
  #model1 = torch.load("chenhsi_model_"+str(num))

#save model
torch.save(model, "chenhsi_model")
#model1 = torch.load('..../Dogcat_resnet18')

#visual check
def predict_image(image):
    image_tensor = test_transforms(image).float()
    image_tensor = image_tensor.unsqueeze_(0)
    input = Variable(image_tensor)
    input = input.to(device)
    output = model(input)
    index = output.data.cpu().numpy().argmax()
    return index

def get_random_images(num):
    data = datasets.ImageFolder(data_dir, transform=test_transforms)
    classes = data.classes
    indices = list(range(len(data)))
    np.random.shuffle(indices)
    idx = indices[:num]
    from torch.utils.data.sampler import SubsetRandomSampler
    sampler = SubsetRandomSampler(idx)
    loader = torch.utils.data.DataLoader(data, 
                   sampler=sampler, batch_size=num)
    dataiter = iter(loader)
    images, labels = dataiter.next()
    return images, labels

to_pil = transforms.ToPILImage()
images, labels = get_random_images(5)
fig=plt.figure(figsize=(10,10))
for ii in range(len(images)):
    image = to_pil(images[ii])
    index = predict_image(image)
    sub = fig.add_subplot(1, len(images), ii+1)
    res = int(labels[ii]) == index
    sub.set_title(str(classes[index]) + ":" + str(res))
    plt.axis('off')
    plt.imshow(image)
plt.show()